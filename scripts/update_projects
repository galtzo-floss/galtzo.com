#!/usr/bin/env ruby
# frozen_string_literal: true

require 'yaml'
require 'net/http'
require 'json'
require 'uri'
require 'date'
require 'time'

class ProjectUpdater
  PROJECTS_FILE = File.expand_path('../src/_data/projects.yml', __dir__)
  PROJECTS_DEV_FILE = File.expand_path('../src/_data/projects_dev.yml', __dir__)

  # API tokens from environment (optional but recommended to avoid rate limits)
  GITHUB_TOKEN = ENV['GITHUB_TOKEN']
  GITLAB_TOKEN = ENV['GITLAB_TOKEN']
  RUBYGEMS_HANDLE = ENV['RUBYGEMS_HANDLE']

  # Skip projects scraped within the last 24 hours
  SCRAPE_THRESHOLD_HOURS = 24

  # Valid fields for surgical updates
  VALID_SURGICAL_FIELDS = %w[
    github_stars gitlab_stars codeberg_stars
    total_downloads daily_downloads release_downloads
    release_date last_commit_on status
  ]

  def initialize(surgical_field: nil, discover_rubygems: false)
    # SAFETY CHECK: projects_dev.yml must exist
    # If it doesn't exist, it means scripts/devswap was run but not run again to restore prod
    # This risks deploying dev/test projects to production
    unless File.exist?(PROJECTS_DEV_FILE)
      abort <<~ERROR
        
        ❌ FATAL ERROR: projects_dev.yml does not exist!
        
        This indicates that scripts/devswap has been run to swap dev and prod projects,
        but has not been run again to restore the production projects.yml file.
        
        Running this script now would risk deploying dev/test projects to production.
        
        To fix this issue:
          1. Run: scripts/devswap
             (This will swap the files back to the correct state)
          2. Then run this script again
        
        Aborting to prevent accidental deployment of dev/test data.
      ERROR
    end

    @projects = load_yaml(PROJECTS_FILE)
    @projects_dev = load_yaml(PROJECTS_DEV_FILE)
    @rate_limit_delay = 1 # seconds between API calls
    @errors = [] # Track errors for summary
    @surgical_field = surgical_field
    @discover_rubygems = discover_rubygems

    # Preserve header comments from YAML files
    @projects_header = extract_yaml_header(PROJECTS_FILE)
    @projects_dev_header = extract_yaml_header(PROJECTS_DEV_FILE)

    if @surgical_field && !VALID_SURGICAL_FIELDS.include?(@surgical_field)
      raise "Invalid surgical field: #{@surgical_field}. Valid fields: #{VALID_SURGICAL_FIELDS.join(', ')}"
    end
  end

  def run
    # First, discover and add missing RubyGems if requested
    if @discover_rubygems
      discover_and_add_missing_gems
    end

    puts "Starting project update..."
    if @surgical_field
      puts "🔬 SURGICAL UPDATE MODE: Only updating '#{@surgical_field}' field"
      puts "   (Ignoring last_scrape_at timestamps)"
    end
    puts "Processing #{@projects.size} projects from #{PROJECTS_FILE}"
    puts "GitHub Token: #{GITHUB_TOKEN ? '✅ Set' : '❌ Not set'}"
    puts "GitLab Token: #{GITLAB_TOKEN ? '✅ Set' : '❌ Not set'}"
    puts "RubyGems Handle: #{RUBYGEMS_HANDLE ? "✅ Set (#{RUBYGEMS_HANDLE})" : '❌ Not set'}"

    skipped_count = 0
    updated_count = 0

    @projects.each_with_index do |project, index|
      # Skip the person entry
      if project['type'] == 'person'
        puts "[#{index + 1}/#{@projects.size}] Skipping person entry: #{project['name']}"
        next
      end

      # Check if project was recently scraped (skip this check in surgical mode)
      if !@surgical_field && recently_scraped?(project)
        puts "[#{index + 1}/#{@projects.size}] ⏭️  Skipping (scraped #{time_ago(project['last_scrape_at'])}): #{project['name']}"
        skipped_count += 1
        next
      end

      puts "\n[#{index + 1}/#{@projects.size}] Processing: #{project['name']}"

      begin
        if @surgical_field
          update_single_field(project, @surgical_field)
        else
          update_project(project)
          # Set the scrape timestamp only for full updates
          project['last_scrape_at'] = Time.now.utc.iso8601
        end

        # If this project exists in projects_dev, sync it
        sync_to_dev(project)

        updated_count += 1
        sleep(@rate_limit_delay) # Rate limiting
      rescue => e
        error_msg = "#{project['name']}: #{e.message}"
        @errors << error_msg
        puts "  ❌ ERROR: #{e.message}"
        puts "  #{e.backtrace.first}"
      end
    end

    save_yaml(PROJECTS_FILE, @projects)
    save_yaml(PROJECTS_DEV_FILE, @projects_dev)

    puts "\n" + "="*80
    puts "📊 Summary"
    puts "="*80
    puts "Updated: #{updated_count}"
    puts "Skipped (recent): #{skipped_count}"
    puts "Errors: #{@errors.size}"

    if @errors.any?
      puts "\n⚠️  Problems Encountered:"
      @errors.each do |error|
        puts "  • #{error}"
      end
    end

    puts "\n✅ Update complete!"
  end

  private

  def discover_and_add_missing_gems
    unless RUBYGEMS_HANDLE
      puts "❌ ERROR: RUBYGEMS_HANDLE environment variable is not set!"
      puts "   Please set it in .env.local to use this feature."
      return
    end

    puts "\n" + "="*80
    puts "🔍 DISCOVERING RUBYGEMS FOR: #{RUBYGEMS_HANDLE}"
    puts "="*80

    # Fetch all gems owned by the user
    rubygems = fetch_user_rubygems(RUBYGEMS_HANDLE)

    if rubygems.empty?
      puts "No gems found for user: #{RUBYGEMS_HANDLE}"
      return
    end

    puts "Found #{rubygems.size} gems owned by #{RUBYGEMS_HANDLE}"

    # Get list of existing gem names in projects
    existing_gems = @projects
      .select { |p| p['language'] == 'Ruby' && p['ecosystem'] == 'rubygems' }
      .map { |p| p['name'] }

    # Find missing gems
    missing_gems = rubygems.reject { |gem_name| existing_gems.include?(gem_name) }

    if missing_gems.empty?
      puts "✅ All gems are already in projects.yml!"
      return
    end

    puts "\n📦 Found #{missing_gems.size} missing gems:"
    missing_gems.each { |name| puts "  • #{name}" }

    puts "\n🔨 Adding missing gems to projects.yml..."

    missing_gems.each_with_index do |gem_name, index|
      puts "\n[#{index + 1}/#{missing_gems.size}] Adding: #{gem_name}"

      begin
        new_project = build_project_from_rubygem(gem_name)
        @projects << new_project
        puts "  ✅ Added #{gem_name}"

        # Also add to projects_dev
        @projects_dev << new_project.dup
        puts "  🔄 Synced to projects_dev.yml"

        sleep(@rate_limit_delay) # Rate limiting
      rescue => e
        error_msg = "Failed to add #{gem_name}: #{e.message}"
        @errors << error_msg
        puts "  ❌ ERROR: #{e.message}"
      end
    end

    # Save the updated projects files
    save_yaml(PROJECTS_FILE, @projects)
    save_yaml(PROJECTS_DEV_FILE, @projects_dev) if @projects_dev

    puts "\n✅ Discovery complete! Added #{missing_gems.size - @errors.select { |e| e.include?('Failed to add') }.size} new gems."
  end

  def fetch_user_rubygems(handle)
    api_url = "https://rubygems.org/api/v1/owners/#{handle}/gems.json"

    puts "  Fetching gems from: #{api_url}"
    data = api_request(api_url)

    return [] unless data && data.is_a?(Array)

    # The API returns an array of gem objects with 'name' field
    data.map { |gem| gem['name'] }.compact
  rescue => e
    error_msg = "Failed to fetch RubyGems for #{handle}: #{e.message}"
    @errors << error_msg
    puts "  ❌ #{error_msg}"
    []
  end

  def build_project_from_rubygem(gem_name)
    # Fetch gem metadata
    gem_info = fetch_rubygems_info(gem_name)
    api_url = "https://rubygems.org/api/v1/gems/#{gem_name}.json"
    gem_data = api_request(api_url)

    unless gem_data
      raise "Failed to fetch gem metadata"
    end

    # Extract key information
    description = gem_data['info'] || gem_data['summary'] || "Ruby gem: #{gem_name}"
    homepage_uri = gem_data['homepage_uri'] || ""
    source_code_uri = gem_data['source_code_uri'] || gem_data['source_code'] || ""

    # Try to determine GitHub URL
    github_url = nil
    github_owner = nil

    # Check various URI fields for GitHub
    [source_code_uri, homepage_uri, gem_data['project_uri']].compact.each do |uri|
      if uri.include?('github.com')
        github_url = uri.sub(/\.git$/, '').sub(%r{/tree/.*}, '').sub(%r{/blob/.*}, '')
        if match = github_url.match(%r{github\.com/([^/]+)/})
          github_owner = match[1]
        end
        break
      end
    end

    # Build forges array
    forges = []
    if github_url
      forges << {
        'type' => 'GitHub',
        'url' => github_url,
        'owner' => github_owner
      }
    end

    # Get release date
    release_date = fetch_rubygems_release_date(gem_name)

    # Determine minimum Ruby version
    required_ruby_version = gem_data['required_ruby_version'] || '>= 0'
    min_version = extract_minimum_version(required_ruby_version)

    # Build the project hash
    project = {
      'name' => gem_name,
      'description' => description,
      'language' => 'Ruby',
      'ecosystem' => 'rubygems',
      'minimum_version' => min_version,
      'role' => 'author', # Assume author since it's owned by the user
      'first_commit_on' => release_date, # Use first release date as placeholder
      'first_commit' => nil, # Will need to be filled manually or via GitHub API
      'funding_sites' => [
        { 'type' => 'OpenCollective', 'url' => 'https://opencollective.com/galtzo-floss' },
        { 'type' => 'Liberapay', 'url' => 'https://liberapay.com/pboling' }
      ],
      'forges' => forges,
      'tags' => determine_tags_from_gem(gem_data),
      'docs_site' => gem_data['documentation_uri'] || nil
    }

    # Add download stats if available
    if gem_info
      project['total_downloads'] = gem_info[:total_downloads]
      project['daily_downloads'] = gem_info[:daily_downloads]
      project['release_downloads'] = gem_info[:release_downloads]
    end

    project['release_date'] = release_date

    # Fetch GitHub info if available
    if github_url
      begin
        github_info = fetch_github_info(github_url)
        project['github_stars'] = github_info[:stars]
        project['last_commit_on'] = github_info[:last_commit]
        project['status'] = github_info[:archived] ? 'archived' : 'active'

        # Try to get first commit info
        repo_path = extract_repo_path(github_url)
        if repo_path
          first_commit = fetch_first_commit(repo_path)
          project['first_commit'] = first_commit[:url] if first_commit
          project['first_commit_on'] = first_commit[:date] if first_commit
        end
      rescue => e
        puts "    ⚠️  Could not fetch GitHub info: #{e.message}"
        project['github_stars'] = 0
        project['status'] = 'active'
      end
    else
      puts "    ⚠️  No GitHub URL found - will need manual configuration"
      project['github_stars'] = 0
      project['status'] = 'active'
    end

    project
  end

  def fetch_first_commit(repo_path)
    # Fetch the first commit using the API
    api_url = "https://api.github.com/repos/#{repo_path}/commits?per_page=1&sha=HEAD"

    # We need to paginate backwards to find the first commit
    # This is a simplified approach - we'll get the last page
    response_data = github_api_request_with_headers(api_url)

    return nil unless response_data[:data] && response_data[:data].is_a?(Array) && response_data[:data].any?

    # Check if there are more pages by looking at Link header
    last_page_url = response_data[:last_page_url]

    if last_page_url
      # Fetch the last page (which contains the first commit)
      last_page_data = github_api_request(last_page_url)
      first_commit = last_page_data.last if last_page_data.is_a?(Array)
    else
      # Only one page, so the last commit is the first
      first_commit = response_data[:data].last
    end

    if first_commit
      commit_date = first_commit.dig('commit', 'committer', 'date')
      {
        url: first_commit['html_url'],
        date: commit_date ? Date.parse(commit_date).strftime('%Y/%m/%d') : nil
      }
    else
      nil
    end
  rescue => e
    puts "    ⚠️  Could not fetch first commit: #{e.message}"
    nil
  end

  def github_api_request_with_headers(url)
    uri = URI(url)
    request = Net::HTTP::Get.new(uri)
    request['Accept'] = 'application/vnd.github.v3+json'
    request['Authorization'] = "token #{GITHUB_TOKEN}" if GITHUB_TOKEN
    request['User-Agent'] = 'Galtzo-Project-Updater'

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    if response.code.to_i == 404
      return { data: nil, last_page_url: nil }
    elsif response.code.to_i != 200
      raise "GitHub API error: #{response.code} - #{response.body[0..200]}"
    end

    # Parse Link header to find last page
    link_header = response['Link']
    last_page_url = nil

    if link_header
      # Extract last page URL from Link header
      # Format: <url>; rel="last"
      if match = link_header.match(/<([^>]+)>;\s*rel="last"/)
        last_page_url = match[1]
      end
    end

    {
      data: JSON.parse(response.body),
      last_page_url: last_page_url
    }
  end

  def extract_minimum_version(version_string)
    # Parse version string like ">= 2.7.0" or "~> 3.0"
    # Return just the major.minor version
    if match = version_string.match(/(\d+\.\d+)/)
      match[1]
    else
      '2.7' # Default to a reasonable version
    end
  end

  def determine_tags_from_gem(gem_data)
    tags = []

    # Check description and summary for common keywords
    text = "#{gem_data['info']} #{gem_data['summary']}".downcase

    # Common tag patterns
    tags << 'rails' if text.include?('rails') || text.include?('activerecord')
    tags << 'activerecord' if text.include?('activerecord')
    tags << 'rspec' if text.include?('rspec')
    tags << 'testing' if text.include?('test') || text.include?('spec')
    tags << 'api' if text.include?('api')
    tags << 'cli' if text.include?('cli') || text.include?('command line')
    tags << 'security' if text.include?('security') || text.include?('auth')
    tags << 'performance' if text.include?('performance') || text.include?('optimization')
    tags << 'debugging' if text.include?('debug') || text.include?('logging')

    # At least return a generic 'ruby' tag
    tags << 'ruby' if tags.empty?

    tags.uniq.sort
  end

  def update_single_field(project, field)
    forges = project['forges'] || []
    github_forge = forges.find { |f| f['type'] == 'GitHub' }
    gitlab_forge = forges.find { |f| f['type'] == 'GitLab' }
    codeberg_forge = forges.find { |f| f['type'] == 'Codeberg' }

    case field
    when 'github_stars'
      raise "Missing GitHub forge for project: #{project['name']}" unless github_forge
      github_info = fetch_github_info(github_forge['url'])
      project['github_stars'] = github_info[:stars]
      puts "  ⭐ GitHub stars: #{github_info[:stars]}"

    when 'gitlab_stars'
      if gitlab_forge
        gitlab_stars = fetch_gitlab_stars(gitlab_forge['url'])
        project['gitlab_stars'] = gitlab_stars
        puts "  ⭐ GitLab stars: #{gitlab_stars}"
      else
        puts "  ⏭️  No GitLab forge for this project"
      end

    when 'codeberg_stars'
      if codeberg_forge
        codeberg_stars = fetch_codeberg_stars(codeberg_forge['url'])
        project['codeberg_stars'] = codeberg_stars
        puts "  ⭐ Codeberg stars: #{codeberg_stars}"
      else
        puts "  ⏭️  No Codeberg forge for this project"
      end

    when 'total_downloads', 'daily_downloads', 'release_downloads'
      if project['language'] == 'Ruby' && project['ecosystem'] == 'rubygems'
        gem_name = project['name']
        gem_info = fetch_rubygems_info(gem_name)
        if gem_info
          project['total_downloads'] = gem_info[:total_downloads]
          project['daily_downloads'] = gem_info[:daily_downloads]
          project['release_downloads'] = gem_info[:release_downloads]
          puts "  📦 #{field}: #{gem_info[field.to_sym]}"
        end
      else
        puts "  ⏭️  Not a RubyGem"
      end

    when 'release_date'
      if project['language'] == 'Ruby' && project['ecosystem'] == 'rubygems'
        gem_name = project['name']
        release_date = fetch_rubygems_release_date(gem_name)
        project['release_date'] = release_date
        puts "  📅 Release date (RubyGems): #{release_date}"
      else
        raise "Missing GitHub forge for project: #{project['name']}" unless github_forge
        release_date = fetch_github_release_date(github_forge['url'])
        project['release_date'] = release_date
        puts "  📅 Release date (GitHub): #{release_date || 'N/A'}"
      end

    when 'last_commit_on'
      raise "Missing GitHub forge for project: #{project['name']}" unless github_forge
      github_info = fetch_github_info(github_forge['url'])
      last_commit = github_info[:last_commit]
      project['last_commit_on'] = last_commit
      puts "  🔨 Last commit: #{last_commit || 'N/A'}"

    when 'status'
      raise "Missing GitHub forge for project: #{project['name']}" unless github_forge
      github_info = fetch_github_info(github_forge['url'])
      last_commit = github_info[:last_commit]

      if github_info[:archived]
        project['status'] = 'archived'
        puts "  📦 Status: archived"
      elsif last_commit.nil? || days_since(last_commit) > 365
        project['status'] = 'stale'
        puts "  ⚠️  Status: stale"
      else
        project['status'] = 'active'
        puts "  ✅ Status: active"
      end
    end
  end

  def update_project(project)
    # Validate theme configuration first
    validate_project_theme(project)

    forges = project['forges'] || []
    github_forge = forges.find { |f| f['type'] == 'GitHub' }
    gitlab_forge = forges.find { |f| f['type'] == 'GitLab' }
    codeberg_forge = forges.find { |f| f['type'] == 'Codeberg' }

    # Step 1: GitHub stars (required)
    raise "Missing GitHub forge for project: #{project['name']}" unless github_forge

    github_info = fetch_github_info(github_forge['url'])
    project['github_stars'] = github_info[:stars]
    puts "  ⭐ GitHub stars: #{github_info[:stars]}"

    # Step 2: GitLab stars (if present)
    if gitlab_forge
      gitlab_stars = fetch_gitlab_stars(gitlab_forge['url'])
      project['gitlab_stars'] = gitlab_stars
      puts "  ⭐ GitLab stars: #{gitlab_stars}"
    end

    # Step 3: Codeberg stars (if present)
    if codeberg_forge
      codeberg_stars = fetch_codeberg_stars(codeberg_forge['url'])
      project['codeberg_stars'] = codeberg_stars
      puts "  ⭐ Codeberg stars: #{codeberg_stars}"
    end

    # Steps 4-6: RubyGems download statistics (for Ruby gems only)
    if project['language'] == 'Ruby' && project['ecosystem'] == 'rubygems'
      gem_name = project['name']
      gem_info = fetch_rubygems_info(gem_name)

      if gem_info
        project['total_downloads'] = gem_info[:total_downloads]
        project['daily_downloads'] = gem_info[:daily_downloads]
        project['release_downloads'] = gem_info[:release_downloads]

        puts "  📦 Total downloads: #{gem_info[:total_downloads]}"
        if gem_info[:daily_downloads]
          puts "  📊 Daily downloads: #{gem_info[:daily_downloads]}"
        else
          puts "  📊 Daily downloads: N/A (not available via public API)"
        end
        puts "  📥 Release downloads: #{gem_info[:release_downloads]}"
      end
    end

    # Step 7: Latest release date
    if project['language'] == 'Ruby' && project['ecosystem'] == 'rubygems'
      # Prefer RubyGems release date
      gem_name = project['name']
      release_date = fetch_rubygems_release_date(gem_name)
      project['release_date'] = release_date
      puts "  📅 Release date (RubyGems): #{release_date}"
    else
      # Use GitHub release date
      release_date = fetch_github_release_date(github_forge['url'])
      project['release_date'] = release_date
      puts "  📅 Release date (GitHub): #{release_date || 'N/A'}"
    end

    # Step 8: Last commit date
    last_commit = github_info[:last_commit]
    project['last_commit_on'] = last_commit
    puts "  🔨 Last commit: #{last_commit || 'N/A'}"

    # Step 9-10: Determine status (archived, stale, or active)
    if github_info[:archived]
      project['status'] = 'archived'
      puts "  📦 Status: archived"
    elsif last_commit.nil? || days_since(last_commit) > 365
      project['status'] = 'stale'
      puts "  ⚠️  Status: stale (#{days_since(last_commit)} days since last commit)"
    else
      project['status'] = 'active'
      puts "  ✅ Status: active"
    end
  end

  def sync_to_dev(project)

    dev_project = @projects_dev.find { |p| p['name'] == project['name'] }
    return unless dev_project

    # Sync the computed fields
    sync_fields = %w[
      github_stars gitlab_stars codeberg_stars
      total_downloads daily_downloads release_downloads
      release_date last_commit_on status last_scrape_at
    ]

    sync_fields.each do |field|
      dev_project[field] = project[field] if project.key?(field)
    end

    puts "  🔄 Synced to projects_dev.yml"
  end

  def recently_scraped?(project)
    return false unless project['last_scrape_at']

    begin
      last_scrape = Time.parse(project['last_scrape_at'])
      hours_ago = (Time.now.utc - last_scrape) / 3600
      hours_ago < SCRAPE_THRESHOLD_HOURS
    rescue
      false
    end
  end

  def time_ago(timestamp)
    return "unknown time" unless timestamp

    begin
      last_scrape = Time.parse(timestamp)
      hours_ago = ((Time.now.utc - last_scrape) / 3600).round(1)

      if hours_ago < 1
        "#{(hours_ago * 60).round} minutes ago"
      else
        "#{hours_ago} hours ago"
      end
    rescue
      "unknown time"
    end
  end

  def fetch_github_info(url)
    repo_path = extract_repo_path(url)
    api_url = "https://api.github.com/repos/#{repo_path}"

    data = github_api_request(api_url)

    # Fetch last commit date
    commits_url = "https://api.github.com/repos/#{repo_path}/commits"
    commits_data = github_api_request(commits_url)
    last_commit = nil
    if commits_data.is_a?(Array) && commits_data.any?
      commit_date = commits_data.first.dig('commit', 'committer', 'date')
      last_commit = Date.parse(commit_date).strftime('%Y/%m/%d') if commit_date
    end

    {
      stars: data['stargazers_count'] || 0,
      archived: data['archived'] || false,
      last_commit: last_commit
    }
  rescue => e
    error_msg = "Failed to fetch GitHub info: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    { stars: 0, archived: false, last_commit: nil }
  end

  def fetch_github_release_date(url)
    repo_path = extract_repo_path(url)
    api_url = "https://api.github.com/repos/#{repo_path}/releases/latest"

    data = github_api_request(api_url)
    return nil unless data && data['published_at']

    Date.parse(data['published_at']).strftime('%Y/%m/%d')
  rescue => e
    error_msg = "Failed to fetch GitHub release date from #{url}: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    nil
  end

  def fetch_gitlab_stars(url)
    # Extract project path from GitLab URL
    # Format: https://gitlab.com/owner/project
    path = url.gsub('https://gitlab.com/', '')
    encoded_path = URI.encode_www_form_component(path)
    api_url = "https://gitlab.com/api/v4/projects/#{encoded_path}"

    data = gitlab_api_request(api_url)
    return 0 unless data

    data['star_count'] || 0
  rescue => e
    error_msg = "Failed to fetch GitLab stars from #{url}: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    0
  end

  def fetch_codeberg_stars(url)
    # Codeberg uses Gitea API
    # Format: https://codeberg.org/owner/project
    match = url.match(%r{codeberg\.org/([^/]+)/([^/]+)})
    return 0 unless match

    owner, repo = match[1], match[2]
    api_url = "https://codeberg.org/api/v1/repos/#{owner}/#{repo}"

    data = api_request(api_url)
    return 0 unless data

    data['stars_count'] || 0
  rescue => e
    error_msg = "Failed to fetch Codeberg stars from #{url}: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    0
  end

  def fetch_rubygems_info(gem_name)
    # Fetch gem stats - this includes all download data available via public API
    api_url = "https://rubygems.org/api/v1/gems/#{gem_name}.json"
    data = api_request(api_url)

    return nil unless data

    total_downloads = data['downloads'] || 0
    version_downloads = data['version_downloads'] || 0

    # Note: RubyGems public API does not provide daily/weekly/monthly download statistics
    # We'll set this to nil to indicate it's not available
    daily_downloads = nil

    {
      total_downloads: total_downloads,
      daily_downloads: daily_downloads,
      release_downloads: version_downloads
    }
  rescue => e
    error_msg = "Failed to fetch RubyGems info for #{gem_name}: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    nil
  end

  def fetch_rubygems_release_date(gem_name)
    # The versions endpoint returns an array of all versions, with the latest first
    api_url = "https://rubygems.org/api/v1/versions/#{gem_name}.json"
    data = api_request(api_url)

    return nil unless data && data.is_a?(Array) && data.any?

    # Get the first non-prerelease version
    latest_version = data.find { |v| !v['prerelease'] }
    return nil unless latest_version && latest_version['created_at']

    Date.parse(latest_version['created_at']).strftime('%Y/%m/%d')
  rescue => e
    error_msg = "Failed to fetch RubyGems release date for #{gem_name}: #{e.message}"
    @errors << error_msg unless @errors.include?(error_msg)
    puts "    ⚠️  #{error_msg}"
    nil
  end

  def github_api_request(url)
    uri = URI(url)
    request = Net::HTTP::Get.new(uri)
    request['Accept'] = 'application/vnd.github.v3+json'
    request['Authorization'] = "token #{GITHUB_TOKEN}" if GITHUB_TOKEN
    request['User-Agent'] = 'Galtzo-Project-Updater'

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    if response.code.to_i == 404
      return nil
    elsif response.code.to_i != 200
      raise "GitHub API error: #{response.code} - #{response.body[0..200]}"
    end

    JSON.parse(response.body)
  end

  def gitlab_api_request(url)
    uri = URI(url)
    request = Net::HTTP::Get.new(uri)
    request['Authorization'] = "Bearer #{GITLAB_TOKEN}" if GITLAB_TOKEN
    request['User-Agent'] = 'Galtzo-Project-Updater'

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    if response.code.to_i == 404
      return nil
    elsif response.code.to_i != 200
      raise "GitLab API error: #{response.code} - #{response.body[0..200]}"
    end

    JSON.parse(response.body)
  end

  def api_request(url)
    uri = URI(url)
    request = Net::HTTP::Get.new(uri)
    request['User-Agent'] = 'Galtzo-Project-Updater'

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    if response.code.to_i == 404
      return nil
    elsif response.code.to_i != 200
      raise "API error: #{response.code} - #{response.body[0..200]}"
    end

    JSON.parse(response.body)
  end

  def extract_repo_path(url)
    # Extract owner/repo from GitHub URL
    # Handles: https://github.com/owner/repo or https://github.com/owner/repo.git
    match = url.match(%r{github\.com[/:]([^/]+)/([^/\.]+)})
    return nil unless match
    "#{match[1]}/#{match[2]}"
  end

  def days_since(date_string)
    return Float::INFINITY if date_string.nil?

    date = Date.parse(date_string.gsub('/', '-'))
    (Date.today - date).to_i
  rescue
    Float::INFINITY
  end

  def load_yaml(file_path)
    YAML.load_file(file_path) || []
  end

  def extract_yaml_header(file_path)
    return "" unless File.exist?(file_path)

    header_lines = []
    in_header = false

    File.readlines(file_path).each do |line|
      # Start capturing after the --- document marker
      if line.strip == '---'
        in_header = true
        next
      end

      # Stop when we hit the first non-comment, non-empty line (start of data)
      if in_header
        if line.strip.start_with?('#') || line.strip.empty?
          header_lines << line
        else
          # We've reached the data section
          break
        end
      end
    end

    # Return the header with a trailing newline if we found comments
    header_lines.empty? ? "" : header_lines.join
  end

  def save_yaml(file_path, data)
    yaml_content = YAML.dump(data)

    # Determine which header to use based on the file path
    header = if file_path == PROJECTS_DEV_FILE
      @projects_dev_header
    elsif file_path == PROJECTS_FILE
      @projects_header
    else
      ""
    end

    # Combine header with YAML content
    if header && !header.empty?
      # The YAML.dump already includes '---' at the start
      # We need to insert the header after the '---' line
      yaml_lines = yaml_content.lines
      if yaml_lines.first&.strip == '---'
        final_content = yaml_lines.first + header + yaml_lines[1..-1].join
      else
        final_content = "---\n" + header + yaml_content
      end
    else
      final_content = yaml_content
    end

    File.write(file_path, final_content)
    puts "\n💾 Saved: #{file_path}"
  end

  # ============================================================================
  # THEME VALIDATION METHODS
  # ============================================================================

  # Validate theme field and theme-specific configuration
  def validate_project_theme(project)
    theme = project['theme']

    # Theme is optional
    return true if theme.nil?

    valid_themes = %w[adopt-me update-me avoid-me family holiday]

    unless valid_themes.include?(theme)
      raise "Invalid theme '#{theme}' for project '#{project['name']}'. Valid themes: #{valid_themes.join(', ')}"
    end

    # Validate theme-specific fields
    case theme
    when 'family'
      validate_family_theme(project)
    when 'holiday'
      validate_holiday_theme(project)
    when 'adopt-me'
      validate_adopt_me_theme(project)
    when 'update-me'
      validate_update_me_theme(project)
    when 'avoid-me'
      validate_avoid_me_theme(project)
    end

    true
  end

  def validate_family_theme(project)
    required_fields = %w[family_id family_name family_position]
    missing_fields = required_fields.select { |field| project[field].nil? }

    if missing_fields.any?
      raise "Family theme requires fields: #{missing_fields.join(', ')} for project '#{project['name']}'"
    end

    unless project['family_position'].is_a?(Integer) && project['family_position'] > 0
      raise "family_position must be a positive integer for project '#{project['name']}'"
    end

    true
  end

  def validate_holiday_theme(project)
    valid_types = %w[christmas halloween newyear birthday celebration]
    holiday_type = project['holiday_type']

    if holiday_type.nil?
      raise "Holiday theme requires 'holiday_type' field for project '#{project['name']}'"
    end

    unless valid_types.include?(holiday_type)
      raise "Invalid holiday_type '#{holiday_type}' for project '#{project['name']}'. Valid types: #{valid_types.join(', ')}"
    end

    # Validate date format if provided
    if project['holiday_date_start']
      begin
        Date.parse(project['holiday_date_start'])
      rescue
        raise "Invalid holiday_date_start format for project '#{project['name']}'. Use YYYY-MM-DD"
      end
    end

    if project['holiday_date_end']
      begin
        Date.parse(project['holiday_date_end'])
      rescue
        raise "Invalid holiday_date_end format for project '#{project['name']}'. Use YYYY-MM-DD"
      end
    end

    true
  end

  def validate_adopt_me_theme(project)
    # adoption_url is optional, no required fields
    if project['adoption_url'] && !project['adoption_url'].start_with?('http')
      raise "adoption_url must be a valid URL for project '#{project['name']}'"
    end
    true
  end

  def validate_update_me_theme(project)
    # stale_since validation
    if project['stale_since']
      begin
        Date.parse(project['stale_since'])
      rescue
        raise "Invalid stale_since format for project '#{project['name']}'. Use YYYY-MM-DD"
      end
    end

    # update_priority validation
    if project['update_priority']
      valid_priorities = %w[low medium high]
      unless valid_priorities.include?(project['update_priority'])
        raise "Invalid update_priority '#{project['update_priority']}' for project '#{project['name']}'. Valid: #{valid_priorities.join(', ')}"
      end
    end

    true
  end

  def validate_avoid_me_theme(project)
    # archived should be boolean if present
    if project['archived'] && ![true, false].include?(project['archived'])
      raise "archived must be true or false for project '#{project['name']}'"
    end

    # replacement_url validation
    if project['replacement_url'] && !project['replacement_url'].start_with?('http')
      raise "replacement_url must be a valid URL for project '#{project['name']}'"
    end

    true
  end
end

# Run the updater
if __FILE__ == $0
  # Parse command-line arguments
  surgical_field = nil
  discover_rubygems = false

  ARGV.each do |arg|
    case arg
    when '--help', '-h'
      puts "Usage: #{$0} [OPTIONS] [FIELD]"
      puts ""
      puts "Update all project data, or surgically update a specific field."
      puts ""
      puts "Options:"
      puts "  --help, -h              Show this help message"
      puts "  --discover-rubygems     Discover and add missing RubyGems to projects.yml"
      puts "                          (Uses RUBYGEMS_HANDLE from environment)"
      puts ""
      puts "Surgical Update Fields:"
      ProjectUpdater::VALID_SURGICAL_FIELDS.each do |field|
        puts "  #{field}"
      end
      puts ""
      puts "Examples:"
      puts "  #{$0}                          # Full update (respects last_scrape_at)"
      puts "  #{$0} --discover-rubygems      # Find and add missing RubyGems"
      puts "  #{$0} release_date             # Update only release_date for all projects"
      puts "  #{$0} github_stars             # Update only github_stars for all projects"
      puts "  #{$0} --discover-rubygems release_date  # Discover gems, then update release_date"
      exit 0
    when '--discover-rubygems'
      discover_rubygems = true
    else
      # Assume it's a surgical field
      surgical_field = arg unless arg.start_with?('--')
    end
  end

  updater = ProjectUpdater.new(surgical_field: surgical_field, discover_rubygems: discover_rubygems)
  updater.run
end



